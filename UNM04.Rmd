---
title: "UNM04"
output: pdf_document
date: "2023-07-03"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(afex)
library(BayesFactor)
library(apa)
library(emmeans)
library("writexl")
load("C:/Users/munizdie/OneDrive - Lancaster University/Experiments/Recognition memory/UNM04-main/UNM04_proc_data.RData")
```

The important columns that need to be taken in all data files are "participant" and "expName".

Training data start in row 6 of excel, 5 if you don't count the header, and finish in row 85, 84 if you don't count the header. The important columns here are: 
"cue_img", (what images are each cue, basically the randomization of the images for that participant)
"cue_order",
"out_order",
"cue_o_mouse.time", (basically the reaction time)
"cue_o_mouse.clicked_name", (which outcome they have clicked)
"correct_answer", (1 if they clicked the outcome programmed, 0 if they clicked the other)
"training_trials.thisN", (trial number)
"cue1",
"cue2",
"outcome"

Test data start in row 86 (85 no header), and finish in row 93 (92 no header). The important columns here are:
"test_mouse.time",
"test_mouse.clicked_name",
"slider.response" ,
"slider.rt",
"test.thisTrialN", (trial number)
"target"

```{r}
training$prob_response[training$RT > 10] <- NA
training$RT[training$RT > 10] <- NA #substitute more than 10 secs for NA
#Plot Training accuracy
MA_training <- training %>%
  group_by(condition, block) %>%
  summarise(mean_accuracy = mean(prob_response, na.rm = TRUE), 
            sd_accuracy = sd(prob_response, na.rm = TRUE)/sqrt(length(prob_response)))
ggplot(MA_training, mapping = aes(x = block, y = mean_accuracy, color = condition)) +
  geom_point() +
  geom_line() +
  geom_errorbar(aes(x= block, y = mean_accuracy, ymin = mean_accuracy-sd_accuracy, ymax = mean_accuracy+sd_accuracy), color = "black", width=.1,position=position_dodge(0.05)) +
  labs(title = "Figure 1", subtitle = "Mean corrected accuracy for the 4 blocks of the training phase")
```
```{r}
#some t test to check that responding is significantly higher than chance
mean_training <- training %>%
  group_by(pNum) %>%
   summarise(mean_response = mean(prob_response, na.rm = TRUE))
t.test(mean_training, mu = .5, alternative = "greater") 
```
```{r}
mean_cert_training <- filter(training, condition == "certain") %>%
  group_by(pNum) %>%
   summarise(mean_response = mean(prob_response, na.rm = TRUE))
t.test(mean_cert_training, mu = .5, alternative = "greater")
```
```{r}
mean_uncert_training <- filter(training, condition == "uncertain") %>%
  group_by(pNum) %>%
   summarise(mean_response = mean(prob_response, na.rm = TRUE))
t.test(mean_uncert_training, mu = .5, alternative = "greater")
```
```{r}
#ANOVA
prob_resp <- training %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
prob_resp$block <- factor(prob_resp$block)
prob_resp$condition <- factor(prob_resp$condition)
prob_resp$pNum <- factor(prob_resp$pNum)
ANOVA_prob_resp <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = prob_resp)
print(ANOVA_prob_resp)
```
```{r}
bay_ANOVA_prob_resp <- anovaBF(formula = mean_response ~ block*condition + pNum,
        data = data.frame(prob_resp),
        whichRandom = "pNum")
print(bay_ANOVA_prob_resp)
```
```{r}
bay_ANOVA_prob_resp[4]/bay_ANOVA_prob_resp[3]
```
```{r}
#plot test accuracy
m_acc_test <- test %>%
  group_by(cue_type) %>%
  summarise(mean_acc = mean(acc, na.rm = TRUE), 
            sd_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
ggplot(data = m_acc_test) +
  geom_col(mapping = aes(x = cue_type, y = mean_acc)) +
  geom_errorbar(aes(x = cue_type, y= mean_acc, ymin = mean_acc - sd_acc, ymax = mean_acc + sd_acc)) +
  coord_cartesian(ylim = c(0, 1))+
  scale_x_discrete (name = "Type of cue") +
  scale_y_continuous(name = "Accuracy") +
  labs(title = "Figure 2", subtitle = "Mean accuracy for each type of cue in test phase")
```
```{r}
#ANOVA accuracy
acc_test <- test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
acc_test$predictiveness <- factor(acc_test$predictiveness)
acc_test$condition <- factor(acc_test$condition)
acc_test$pNum <- factor(acc_test$pNum)
ANOVA_acc_test <- aov_car(formula = acc ~ condition + Error(pNum*predictiveness), data = acc_test)
print(ANOVA_acc_test)
```
```{r}
bay_ANOVA_acc_test <- anovaBF(formula = acc ~ condition*predictiveness + pNum,
        data = data.frame(acc_test),
        whichRandom = "pNum")
print(bay_ANOVA_acc_test)
```
```{r}
bay_ANOVA_acc_test[4]/bay_ANOVA_acc_test[3]
```
```{r}
#plot test mem_score
m_mem_test <- test %>%
  group_by(cue_type) %>%
  summarise(mean_mem_score = mean(mem_score, na.rm = TRUE), 
            sd_mem_score = sd(mem_score, na.rm = TRUE)/sqrt(length(mem_score)))
ggplot(data = m_mem_test) +
  geom_col(mapping = aes(x = cue_type, y = mean_mem_score)) +
  geom_errorbar(aes(x = cue_type, y= mean_mem_score, ymin = mean_mem_score - sd_mem_score, ymax = mean_mem_score + sd_mem_score)) +
  coord_cartesian(ylim = c(0, 10))+
  scale_x_discrete (name = "Type of cue") +
  scale_y_continuous(name = "Memory score") +
  labs(title = "Figure 3", subtitle = "Mean memory score for each type of cue in test phase")
```
```{r}
#ANOVA mem_score
mem_score_test <- test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(mem_score, na.rm = TRUE))
mem_score_test$predictiveness <- factor(mem_score_test$predictiveness)
mem_score_test$condition <- factor(mem_score_test$condition)
mem_score_test$pNum <- factor(mem_score_test$pNum)
ANOVA_mem_score_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness), data = mem_score_test)
print(ANOVA_mem_score_test)
```
```{r}
bay_ANOVA_mem_score_test <- anovaBF(formula = mem_score ~ condition*predictiveness + pNum,
        data = data.frame(mem_score_test),
        whichRandom = "pNum")
print(bay_ANOVA_mem_score_test)
```
```{r}
bay_ANOVA_mem_score_test[4]/bay_ANOVA_mem_score_test[3]
```
```{r}
#plot test mem_score but take out the errors
c_test <- filter(test, acc == 1)
c_m_mem_test <- c_test %>%
  group_by(cue_type) %>%
  summarise(mean_mem_score = mean(mem_score, na.rm = TRUE), 
            sd_mem_score = sd(mem_score, na.rm = TRUE)/sqrt(length(mem_score)))
ggplot(data = c_m_mem_test) +
  geom_col(mapping = aes(x = cue_type, y = mean_mem_score)) +
  geom_errorbar(aes(x = cue_type, y= mean_mem_score, ymin = mean_mem_score - sd_mem_score, ymax = mean_mem_score + sd_mem_score)) +
  coord_cartesian(ylim = c(0, 10))+
  scale_x_discrete (name = "Type of cue") +
  scale_y_continuous(name = "Memory score") +
  labs(title = "Figure 3", subtitle = "Mean memory score for each type of cue in test phase")
```
```{r}
#ANOVA mem_score
c_mem_score_test <- c_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(mem_score, na.rm = TRUE))
c_mem_score_test$predictiveness <- factor(c_mem_score_test$predictiveness)
c_mem_score_test$condition <- factor(c_mem_score_test$condition)
c_mem_score_test$pNum <- factor(c_mem_score_test$pNum)
c_ANOVA_mem_score_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness), data = c_mem_score_test)
print(c_ANOVA_mem_score_test)
```
```{r}
#interaction analysis
c_mem_score_interaction_p <- emmeans(c_ANOVA_mem_score_test, ~ predictiveness|condition)
pairs(c_mem_score_interaction_p, adjust = "bon")
```
```{r}
c_mem_test_interaction_c <- emmeans(c_ANOVA_mem_score_test, ~ condition|predictiveness)
pairs(c_mem_test_interaction_c, adjust = "bon")
```
```{r}
c_bay_ANOVA_mem_score_test <- anovaBF(formula = mem_score ~ condition*predictiveness + pNum,
        data = data.frame(c_mem_score_test),
        whichRandom = "pNum")
print(c_bay_ANOVA_mem_score_test)
```
```{r}
c_bay_ANOVA_mem_score_test[4]/c_bay_ANOVA_mem_score_test[3]
```